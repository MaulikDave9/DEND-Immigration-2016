{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Immigration Data Analytics based on I-94 Forms For Year 2016\n",
    "\n",
    "#### Project Summary\n",
    "This project creates data lake for Immigration to USA during the year 2016.  Currently data\n",
    "is residing on S3.  ETL pipeline is designed to extract data from S3, clean up/process using Spark,\n",
    "and loading back to S3 as set of tables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import configparser\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime, timedelta, date\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.functions import udf, col, monotonically_increasing_id\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# AWS credentials from configure file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']     = config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = config['AWS']['AWS_SECRET_ACCESS_KEY']\n",
    "    \n",
    "# Input from local system OR S3\n",
    "DATA_LOCAL = False\n",
    "\n",
    "if DATA_LOCAL:\n",
    "    input_datapath_i94                      = config['LOCAL_DATAPATH']['INPUT_DATA_I94']\n",
    "    input_datapath_airportcode              = config['LOCAL_DATAPATH']['INPUT_DATA_AIRPORT_CODE']\n",
    "    input_datapath_citcode                  = config['LOCAL_DATAPATH']['INPUT_DATA_CIT_CODE']\n",
    "    input_datapath_iatacode                 = config['LOCAL_DATAPATH']['INPUT_DATA_IATA_CITY']\n",
    "    input_datapath_us_city_demographies     = config['LOCAL_DATAPATH']['INPUT_DATA_US_CITY']\n",
    "    output_datapath                         = config['LOCAL_DATAPATH']['OUTPUT_DATA']\n",
    "else:\n",
    "    input_datapath_i94                      = config['S3_DATAPATH']['INPUT_DATA_I94']\n",
    "    input_datapath_airportcode              = config['S3_DATAPATH']['INPUT_DATA_AIRPORT_CODE']\n",
    "    input_datapath_citcode                  = config['S3_DATAPATH']['INPUT_DATA_CIT_CODE']\n",
    "    input_datapath_iatacode                 = config['S3_DATAPATH']['INPUT_DATA_IATA_CITY']\n",
    "    input_datapath_us_city_demographies     = config['S3_DATAPATH']['INPUT_DATA_US_CITY']\n",
    "    output_datapath                         = config['S3_DATAPATH']['OUTPUT_DATA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7f9b401fae48>\n"
     ]
    }
   ],
   "source": [
    "# Spark session\n",
    "spark = SparkSession.builder\\\n",
    "                    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "                    .config(\"spark.hadoop.fs.s3a.impl\",\"org.apache.hadoop.fs.s3a.S3AFileSystem\")\\\n",
    "                    .config(\"spark.hadoop.fs.s3a.access.key\", os.environ[\"AWS_ACCESS_KEY_ID\"])\\\n",
    "                    .config(\"spark.hadoop.fs.s3a.secret.key\", os.environ[\"AWS_SECRET_ACCESS_KEY\"])\\\n",
    "                    .enableHiveSupport().getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", os.environ['AWS_ACCESS_KEY_ID'])\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", os.environ['AWS_SECRET_ACCESS_KEY'])\n",
    "\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "These tables can be leveraged by BI and Analytics team to find the US immigration \n",
    "patterns for different US cities (airports), explore us city demographics corelation with immigrant arrival for the city.\n",
    "This project will make it possible to find insights that simply is not possible from given raw data. \n",
    "E.g. Immigration visa types per various US City airports.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "    (1) Immigration data: SAS file for each month of 2016. \n",
    "        This data comes from US National Tourism and Trade Office, and the original\n",
    "        source: https://travel.trade.gov/research/reports/i94/historical/2016.html \n",
    "    \n",
    "    (2) US City Demographic Data: CSV file with information on US City demographics:\n",
    "        population -male, female, median income etc. \n",
    "        Source: https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/\n",
    "     \n",
    "    (3) Airport Code: CSV file with table of airport codes and corresponding cities\n",
    "        source: https://datahub.io/core/airport-codes#data\n",
    "        \n",
    "    (4) IATA code: CSV file, lookup to get IATA code to airport name, city, state\n",
    "        Source: https://www.airportcodes.us/us-airports.htm\n",
    "        \n",
    "    (5) Country Code: CSV file that's look up for Country Name based on I94CIT 3 digit value number\n",
    "        Source: I94_SAS_Lables_Descriptions.SAS.\n",
    " \n",
    " Please see below for the example of this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Identify data quality issues & Basic clean up the data. \n",
    "There were several missing values, they replaced by 'NA' or appropriate values and data types. \n",
    "Duplicate records were removed.\n",
    "Airport codes (iata code) is key element and regular expression was used to filter out invalid codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Immigration Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# To covert arrival and departure date from df_i94 double to date!\n",
    "#Reference: https://knowledge.udacity.com/questions/66798\n",
    "\n",
    "def convert_datetime(x):\n",
    "    try:\n",
    "        if x == 'null':\n",
    "            x = 0\n",
    "        start = datetime(1960, 1, 1)\n",
    "        return start + timedelta(days=int(x))\n",
    "    except:\n",
    "        return None\n",
    "udf_datetime_from_sas = udf(lambda x: convert_datetime(x), T.DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3a://udacity-project-immigration2016-parquet-files/*/*.parquet\n"
     ]
    }
   ],
   "source": [
    "print(input_datapath_i94)\n",
    "df_i94 = spark.read.parquet(input_datapath_i94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: date (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: date (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n",
      "+---------+------+------+------+-------+----------+-------+-------+----------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+\n",
      "|    cicid| i94yr|i94cit|i94res|i94port|   arrdate|i94mode|i94addr|   depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|       admnum|fltno|visatype|\n",
      "+---------+------+------+------+-------+----------+-------+-------+----------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+\n",
      "|5680949.0|2016.0| 117.0| 117.0|    NYC|2016-07-24|    1.0|     NY|      null|  30.0|    3.0|  1.0|20160724|     NPL| null|      G|   null|   null|   null| 1986.0|     D/S|     F|  null|     IG|2.947450085E9| 3940|      F1|\n",
      "|5680950.0|2016.0| 245.0| 245.0|    DET|2016-07-24|    1.0|     IL|2016-08-13|  46.0|    2.0|  1.0|20160813|    null| null|      G|      O|   null|      M| 1970.0|01232017|     M| 78652|     DL|2.947451085E9|  188|      B2|\n",
      "|5680953.0|2016.0| 245.0| 245.0|    SEA|2016-07-24|    1.0|     WA|2016-08-04|  36.0|    2.0|  1.0|20160804|    null| null|      G|      O|   null|      M| 1980.0|01232017|     F|130660|     OZ|2.947454785E9|  272|      B2|\n",
      "+---------+------+------+------+-------+----------+-------+-------+----------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_i94 = df_i94.withColumn('arrdate', udf_datetime_from_sas(df_i94.arrdate))\n",
    "df_i94 = df_i94.withColumn('depdate', udf_datetime_from_sas(df_i94.depdate))\n",
    "df_i94.dropna()\n",
    "df_i94.printSchema()\n",
    "df_i94.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+-------+----------+-------+-------+----------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+\n",
      "|    cicid| i94yr|i94cit|i94res|i94port|   arrdate|i94mode|i94addr|   depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|       admnum|fltno|visatype|\n",
      "+---------+------+------+------+-------+----------+-------+-------+----------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+\n",
      "|5680949.0|2016.0| 117.0| 117.0|    NYC|2016-07-24|    1.0|     NY|      null|  30.0|    3.0|  1.0|20160724|     NPL|   NA|      G|     NA|     NA|     NA| 1986.0|     D/S|     F|    NA|     IG|2.947450085E9| 3940|      F1|\n",
      "|5680950.0|2016.0| 245.0| 245.0|    DET|2016-07-24|    1.0|     IL|2016-08-13|  46.0|    2.0|  1.0|20160813|      NA|   NA|      G|      O|     NA|      M| 1970.0|01232017|     M| 78652|     DL|2.947451085E9|  188|      B2|\n",
      "|5680953.0|2016.0| 245.0| 245.0|    SEA|2016-07-24|    1.0|     WA|2016-08-04|  36.0|    2.0|  1.0|20160804|      NA|   NA|      G|      O|     NA|      M| 1980.0|01232017|     F|130660|     OZ|2.947454785E9|  272|      B2|\n",
      "|5680954.0|2016.0| 135.0| 135.0|    ORL|2016-07-24|    1.0|     FL|2016-08-07|  17.0|    2.0|  1.0|20160808|      NA|   NA|      O|      O|     NA|      M| 1999.0|10212016|     F|294090|     MT|2.947455685E9|  176|      WT|\n",
      "|5680956.0|2016.0| 213.0| 213.0|    MIA|2016-07-24|    1.0|     FL|2016-10-01|  23.0|    2.0|  1.0|20160724|     HYD|   NA|      G|      O|     NA|      M| 1993.0|01232017|     M| 21180|     QR|2.947457485E9|  777|      B2|\n",
      "+---------+------+------+------+-------+----------+-------+-------+----------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cleaning up immigration data replace missing values with NA or 0!\n",
    "df_i94 = df_i94.withColumn('i94port', trim(col('i94port')))\n",
    "df_i94 = df_i94.na.fill({\\\n",
    "         'i94yr':      0.0,\\\n",
    "         'i94addr':   'NA',\\\n",
    "         'depdate':   'NA',\\\n",
    "         'i94bir':    'NA',\\\n",
    "         'i94visa':    0.0,\\\n",
    "         'count':      0.0,\\\n",
    "         'dtadfile':  'NA',\\\n",
    "         'visapost':  'NA',\\\n",
    "         'occup':     'NA',\\\n",
    "         'entdepa':   'NA',\\\n",
    "         'entdepd':   'NA',\\\n",
    "         'entdepu':   'NA',\\\n",
    "         'matflag':   'NA',\\\n",
    "         'biryear':   'NA',\\\n",
    "         'dtaddto':   'NA',\\\n",
    "         'gender':    'NA',\\\n",
    "         'insnum':    'NA',\\\n",
    "         'airline':   'NA',\\\n",
    "         'admnum':     0.0,\\\n",
    "         'fltno':     'NA',\\\n",
    "         'visatype':  'NA'\\\n",
    "         })\n",
    "df_i94.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Airport Information - Name, Type, IATA Code of airport, Country, Region & Municipality of airport location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_airports = spark.read.format('csv').options(header='true').load('s3a://udacity-project-csv-files/airport-codes.csv')\n",
    "df_airports.dropna()\n",
    "df_airports.printSchema()\n",
    "df_airports.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+-------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region| municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+-------------+--------+---------+----------+--------------------+\n",
      "|  03N|small_airport|      Utirik Airport|           4|       OC|         MH|    MH-UTI|Utirik Island|    K03N|      UTK|       03N|  169.852005, 11.222|\n",
      "| 07FA|small_airport|Ocean Reef Club A...|           8|       NA|         US|     US-FL|    Key Largo|    07FA|      OCA|      07FA|-80.274803161621,...|\n",
      "|  0AK|small_airport|Pilot Station Air...|         305|       NA|         US|     US-AK|Pilot Station|    null|      PQS|       0AK|-162.899994, 61.9...|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+-------------+--------+---------+----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# airport table data clean up\n",
    "# since iata_code is very important, drop if no iata_code = null\n",
    "expr = r'^[A-Z]'\n",
    "df_airports = df_airports.filter(df_airports.iata_code.isNotNull())\n",
    "df_airports = df_airports.filter(df_airports['iata_code'].rlike(expr))\n",
    "df_airports.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### US City Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Number of Veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n",
      "+-------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+------------------+-----+\n",
      "|         City|        State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|              Race|Count|\n",
      "+-------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+------------------+-----+\n",
      "|Silver Spring|     Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|Hispanic or Latino|25924|\n",
      "|       Quincy|Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|             White|58723|\n",
      "|       Hoover|      Alabama|      38.5|          38040|            46799|           84839|              4819|        8229|                  2.58|        AL|             Asian| 4759|\n",
      "+-------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_city = spark.read.format('csv').options(header='true',delimiter=';').load('s3a://udacity-project-csv-files/us-cities-demographics.csv')\n",
    "df_city.dropna()\n",
    "df_city.printSchema()\n",
    "df_city.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+------------------+-----+\n",
      "|         City|        State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|              Race|Count|\n",
      "+-------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+------------------+-----+\n",
      "|Silver Spring|     Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|Hispanic or Latino|25924|\n",
      "|       Quincy|Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|             White|58723|\n",
      "|       Hoover|      Alabama|      38.5|          38040|            46799|           84839|              4819|        8229|                  2.58|        AL|             Asian| 4759|\n",
      "+-------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean up df_city - removing row where city is null\n",
    "df_city = df_city.filter(df_city.City.isNotNull())\n",
    "df_city.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#####  I94CIT Code Country Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- I94CIT: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+------+-----------+\n",
      "|I94CIT|    Country|\n",
      "+------+-----------+\n",
      "|   582|     MEXICO|\n",
      "|   236|AFGHANISTAN|\n",
      "|   101|    ALBANIA|\n",
      "+------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_i94cit = spark.read.format('csv').options(header='true').load('s3a://udacity-project-csv-files/country_code.csv')\n",
    "df_i94cit = df_i94cit.filter(df_i94cit.I94CIT.isNotNull())\n",
    "df_i94cit.dropna()\n",
    "df_i94cit.printSchema()\n",
    "df_i94cit.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### US City Airport IATA Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Code: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      "\n",
      "+----+--------------------+-------------+-----+\n",
      "|Code|                Name|         City|State|\n",
      "+----+--------------------+-------------+-----+\n",
      "| 0AK|Pilot Station Air...|Pilot Station|   AK|\n",
      "| 16A| Nunapitchuk Airport|  Nunapitchuk|   AK|\n",
      "| 1G4|Grand Canyon West...|Peach Springs|   AZ|\n",
      "+----+--------------------+-------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_iata = spark.read.format('csv').options(header='true').load('s3a://udacity-project-csv-files/iata_code_city.csv')\n",
    "df_iata = df_iata.filter(df_iata.Code.isNotNull())\n",
    "df_iata.dropna()\n",
    "df_iata.printSchema()\n",
    "df_iata.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Data is modeled with star schema.  It offers efficient way to organize the raw data and supports the intended queries.  \n",
    "\"immigration_table\" is a fact table with most relevant busienss data and \"immigrant_table\",\"airport_table\", \"city_table\" are supporting dimension tables.\n",
    "\n",
    "![ERD](Immigration-ERD.jpg)\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "Immigration and airport Staging tables were created to get value from data sources and load in to tables appropriately.\n",
    "\n",
    "Look up tables were created for linking IATA code (airport code) to add to the city table. \n",
    "Immigration table had only numeric code for the country, country code table was created based on I94 description to find the\n",
    "country of origin for a immigrant table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model.\n",
    "\n",
    "##### Create Immigration Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- country_code: integer (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- i94model: double (nullable = true)\n",
      " |-- State: string (nullable = false)\n",
      " |-- arrival_date: date (nullable = true)\n",
      " |-- departure_date: date (nullable = true)\n",
      " |-- visa: double (nullable = false)\n",
      " |-- visa_type: string (nullable = false)\n",
      " |-- airline: string (nullable = false)\n",
      " |-- flight_number: string (nullable = false)\n",
      " |-- gender: string (nullable = false)\n",
      " |-- birth_year: integer (nullable = true)\n",
      " |-- occupation: string (nullable = false)\n",
      " |-- ins_number: string (nullable = false)\n",
      " |-- admission_number: float (nullable = false)\n",
      "\n",
      "+-----+------------+---------+--------+-----+------------+--------------+----+---------+-------+-------------+------+----------+----------+----------+----------------+\n",
      "|cicid|country_code|iata_code|i94model|State|arrival_date|departure_date|visa|visa_type|airline|flight_number|gender|birth_year|occupation|ins_number|admission_number|\n",
      "+-----+------------+---------+--------+-----+------------+--------------+----+---------+-------+-------------+------+----------+----------+----------+----------------+\n",
      "|    1|         254|      LOS|     1.0|   CA|  2016-07-01|    2016-07-05| 2.0|       WT|     OZ|        00202|     M|      1978|        NA|        NA|      6.30929E10|\n",
      "|    2|         140|      NYC|     1.0|   NY|  2016-07-01|    2016-07-22| 2.0|       WT|     DL|        09858|     F|      1971|        NA|        NA|      6.30929E10|\n",
      "|    2|         101|      ATL|     1.0|   MI|  2016-02-14|          null| 3.0|       F1|     DL|          241|     F|      1995|        NA|        NA|    4.91319776E8|\n",
      "|    2|         213|      XXX|    null|   NA|  2016-03-30|          null| 2.0|       B2|     NA|           NA|    NA|      1952|        NA|        NA|    1.14019968E9|\n",
      "|    2|         207|      XXX|    null|   NA|  2016-05-31|          null| 3.0|       F1|     NA|           NA|    NA|      1989|        NA|        NA|    1.14163418E9|\n",
      "+-----+------------+---------+--------+-----+------------+--------------+----+---------+-------+-------------+------+----------+----------+----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_i94.createOrReplaceTempView(\"staging_immigration_table\")\n",
    "immigration_table = spark.sql(\"\"\"SELECT \n",
    "                                    cast(cicid AS INT)     AS cicid,\n",
    "                                    cast(i94cit AS INT)    AS country_code,\n",
    "                                    i94port                AS iata_code,\n",
    "                                    i94mode                AS i94model,\n",
    "                                    i94addr                AS State,\n",
    "                                    arrdate                AS arrival_date,\n",
    "                                    depdate                AS departure_date,\n",
    "                                    i94visa                AS visa,\n",
    "                                    visatype               AS visa_type,\n",
    "                                    airline                AS airline,\n",
    "                                    fltno                  AS flight_number,\n",
    "                                    gender                 AS gender,\n",
    "                                    cast(biryear AS INT)   AS birth_year,\n",
    "                                    occup                  AS occupation,\n",
    "                                    insnum                 AS ins_number,\n",
    "                                    cast(admnum AS FLOAT)  AS admission_number\n",
    "                                 FROM staging_immigration_table ORDER BY cicid\n",
    "                             \"\"\").dropDuplicates()\n",
    "immigration_table.printSchema()\n",
    "immigration_table.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Create Airport Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- airport_name: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- muncipality: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- coordinate_x: string (nullable = true)\n",
      " |-- coordinate_y: string (nullable = true)\n",
      "\n",
      "+--------------------+------+----------------+---------+------------------+-------------------+\n",
      "|        airport_name|region|     muncipality|iata_code|      coordinate_x|       coordinate_y|\n",
      "+--------------------+------+----------------+---------+------------------+-------------------+\n",
      "|Andorra la Vella ...| AD-07|Andorra La Vella|      ALV|          1.533551|          42.511174|\n",
      "|Yas Island Seapla...| AE-AZ|       Abu Dhabi|      AYM|           54.6103|             24.467|\n",
      "|Abu Dhabi Interna...| AE-AZ|       Abu Dhabi|      AUH|54.651100158691406| 24.433000564575195|\n",
      "|      Bateen Airport| AE-AZ|            null|      AZI|54.458099365234375| 24.428300857543945|\n",
      "|Al Ain Internatio...| AE-AZ|          Al Ain|      AAN| 55.60919952392578| 24.261699676513672|\n",
      "+--------------------+------+----------------+---------+------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_airports.createOrReplaceTempView(\"staging_airport_table\")\n",
    "airport_table = spark.sql(\"\"\"SELECT \n",
    "                                    name         AS airport_name,\n",
    "                                    iso_region   AS region,\n",
    "                                    municipality AS muncipality,\n",
    "                                    iata_code    AS iata_code,\n",
    "                                    SPLIT(coordinates,',')[0]  AS coordinate_x,\n",
    "                                    SPLIT(coordinates,',')[1]  AS coordinate_y\n",
    "                             FROM staging_airport_table ORDER BY region\n",
    "                            \"\"\").dropDuplicates()\n",
    "airport_table.printSchema()\n",
    "airport_table.show(5)\n",
    "#airport_table = airport_table.filter(airport_table.iata_code.isNotNull()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Create City Demographics Table, add Airport Code for IATA lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- state_abbr: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- airport_name: string (nullable = true)\n",
      " |-- median_age: string (nullable = true)\n",
      " |-- total_population: string (nullable = true)\n",
      " |-- foreign_born: string (nullable = true)\n",
      "\n",
      "+-------+--------+----------+---------+--------------------+----------+----------------+------------+\n",
      "|   city|   state|state_abbr|iata_code|        airport_name|median_age|total_population|foreign_born|\n",
      "+-------+--------+----------+---------+--------------------+----------+----------------+------------+\n",
      "|Abilene|   Texas|        TX|      ABI|Abilene Regional ...|      31.3|          125876|        8129|\n",
      "| Albany| Georgia|        GA|      ALB|Albany Internatio...|      33.3|           71109|         861|\n",
      "| Albany| Georgia|        GA|      ABY|Southwest Georgia...|      33.3|           71109|         861|\n",
      "| Albany|New York|        NY|      ALB|Albany Internatio...|      32.8|           98452|       11948|\n",
      "| Albany|New York|        NY|      ABY|Southwest Georgia...|      32.8|           98452|       11948|\n",
      "+-------+--------+----------+---------+--------------------+----------+----------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_city.createOrReplaceTempView(\"staging_city\")\n",
    "df_iata.createOrReplaceTempView(\"staging_iata\")\n",
    "city_table = spark.sql(\"\"\"SELECT \n",
    "                             sc.City               AS city,\n",
    "                             sc.State              AS state,\n",
    "                             sc.`State Code`       AS state_abbr,\n",
    "                             si.Code               AS iata_code,\n",
    "                             si.Name               AS airport_name,\n",
    "                             sc.`Median Age`       AS median_age,\n",
    "                             sc.`Total Population` AS total_population,\n",
    "                             sc.`Foreign-born`     AS foreign_born\n",
    "                       FROM staging_city AS sc\n",
    "                       JOIN staging_iata AS si ON sc.City = si.City \n",
    "                       ORDER BY city\n",
    "                       \"\"\").dropDuplicates()\n",
    "city_table.printSchema()\n",
    "city_table.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Immigrant Table (Immigration information and add name of country of origin based on i94cit value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- country_of_origin: string (nullable = true)\n",
      " |-- port_of_entry: string (nullable = true)\n",
      " |-- arrival_date: date (nullable = true)\n",
      " |-- visa: double (nullable = false)\n",
      " |-- visa_for: string (nullable = false)\n",
      " |-- visa_type: string (nullable = false)\n",
      " |-- gender: string (nullable = false)\n",
      " |-- birth_year: integer (nullable = true)\n",
      " |-- occupation: string (nullable = false)\n",
      "\n",
      "+-----+-----------------+-------------+------------+----+--------+---------+------+----------+----------+\n",
      "|cicid|country_of_origin|port_of_entry|arrival_date|visa|visa_for|visa_type|gender|birth_year|occupation|\n",
      "+-----+-----------------+-------------+------------+----+--------+---------+------+----------+----------+\n",
      "|    2|   CZECH REPUBLIC|          NYC|  2016-07-01| 2.0|Pleasure|       WT|     F|      1971|        NA|\n",
      "|    2|          ALBANIA|          ATL|  2016-02-14| 3.0| Student|       F1|     F|      1995|        NA|\n",
      "|    2|            INDIA|          XXX|  2016-03-30| 2.0|Pleasure|       B2|    NA|      1952|        NA|\n",
      "|    2|        SINGAPORE|          XXX|  2016-05-31| 3.0| Student|       F1|    NA|      1989|        NA|\n",
      "|    3|   UNITED KINGDOM|          ORL|  2016-07-01| 2.0|Pleasure|       WT|     M|      2006|        NA|\n",
      "+-----+-----------------+-------------+------------+----+--------+---------+------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_table.createOrReplaceTempView(\"staging_immigration\")\n",
    "df_i94cit.createOrReplaceTempView(\"staging_cit\")\n",
    "immigrant_table = spark.sql(\"\"\"SELECT \n",
    "                                    it.cicid,\n",
    "                                    cit.Country  AS country_of_origin,\n",
    "                                    it.iata_code AS port_of_entry,\n",
    "                                    it.arrival_date,\n",
    "                                    it.visa,  \n",
    "                                    CASE it.visa\n",
    "                                        WHEN '1.0' THEN 'Business'\n",
    "                                        WHEN '2.0' THEN 'Pleasure'\n",
    "                                        WHEN '3.0' THEN 'Student'\n",
    "                                        ELSE 'Unknown'\n",
    "                                    END AS visa_for,\n",
    "                                    it.visa_type,             \n",
    "                                    it.gender,   \n",
    "                                    it.birth_year,\n",
    "                                    it.occupation\n",
    "                                 FROM staging_immigration AS it\n",
    "                                 JOIN staging_cit         AS cit ON (it.country_code = cit.i94CIT)\n",
    "                                 ORDER BY cicid\n",
    "                             \"\"\").dropDuplicates()\n",
    "immigrant_table.dropna()\n",
    "immigrant_table.printSchema()\n",
    "immigrant_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Parquet file writes\n",
    "immigrantParquetPath = \"{}{}\".format('s3a://udacity-project-output/', 'immigrant.parquet')\n",
    "airportParquetPath   = \"{}{}\".format('s3a://udacity-project-output/', 'airport.parquet')                                     \n",
    "cityParquetPath      = \"{}{}\".format('s3a://udacity-project-output/', 'city.parquet')                                     \n",
    "\n",
    "immigrant_table.write.mode('overwrite').partitionBy('country_of_origin').parquet(immigrantParquetPath) \n",
    "airport_table.write.mode('overwrite').partitionBy('iata_code').parquet(airportParquetPath)           \n",
    "city_table.write.mode('overwrite').partitionBy('city').parquet(cityParquetPath)                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Data quality checks  to ensure the pipeline ran as expected.\n",
    "Many of the Quality Checks were perfomed earlier to replace missing values, removing duplicates etc.\n",
    "Airport data frame was checked using regular expression to filter out invalid codes.\n",
    "Following is just very naive basic checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform quality checks here\n",
    "\n",
    "#Immigration primary cicid is not null, following count shall be Zero!\n",
    "immigration_table.createOrReplaceTempView(\"staging_immigration\")\n",
    "cicid_count_check = spark.sql(\"\"\"SELECT COUNT(*) FROM staging_immigration WHERE cicid IS NULL\"\"\")\n",
    "cicid_count_check.show(1)\n",
    "\n",
    "airport_code_validation = spark.sql(\"\"\"SELECT COUNT(*) FROM staging_immigration WHERE iata_code = 0\"\"\")\n",
    "airport_code_validation.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "\n",
    "    (1) Immigration Table - Created from the I94 SAS files.\n",
    "        Fields:\n",
    "    \n",
    "         cicid: integer - unique ID for each immigrant used as PK for this table\n",
    "         country_code: integer - I94CIT field from I94, country immigrating from e.g. 582 -> Mexico\n",
    "         iata_code: string - Airport code e.g. BOS -> Boston, NYC - New York City\n",
    "         i94model: double - mode of entry e.g. 1-> Air, 2-> Sea, 3-> Land\n",
    "         State: string - Standard US state e.g. CA -> California, NY -> New York\n",
    "         arrival_date: date - data of arrival YYYY-MM-DD\n",
    "         departure_date: date - date of departure YYYY-MM-DD\n",
    "         visa: double- visa code, e.g. 1 = Business, 2 = Pleasure\n",
    "         visa_type: string visa type per visa code e.g. Business, Student\n",
    "         airline: string - Airline used to arrive in US\n",
    "         flight_number: string - Flight Number of airline used to arrive in US\n",
    "         gender: string - Non immigrant sex e.g. M, F\n",
    "         birth_year: integer - 4 digit year of birth\n",
    "         occupation: string - occupation that will be performed in US\n",
    "         ins_number: string - INS number\n",
    "         admission_number: float - Admission number\n",
    "         \n",
    "    (2) Airport Table - Created from airport code csv file\n",
    "        Fields:\n",
    "        \n",
    "        airport_name: string e.g. Abu Dhabi International Airport\n",
    "        region: string - Region of the airport e.g AE-AZ\n",
    "        muncipality: string - e.g. Abu Dhabi\n",
    "        iata_code: string - 3-digit Airport code, e.g. ALV\n",
    "        coordinate_x: string - can be used to find location airport\n",
    "        coordinate_y: string  - can be used to find location airport\n",
    "        \n",
    "    (3) City Table - created from US city demographics csv file\n",
    "        Fields:\n",
    "          \n",
    "         city: string - City for the airport e.g. San Francisco \n",
    "         state: string - State e.g California\n",
    "         state_abbr: string - State abbr. e.g CA\n",
    "         iata_code: string - 3-digit Airport code e.g. SFO\n",
    "         airport_name: string e.g. San Francisco International Airport\n",
    "         median_age: string - median age for the population in that city\n",
    "         total_population: string - total population for this city\n",
    "         foreign_born: string - how many are foreign born in that city\n",
    "         \n",
    "    (4) Immigrant Table - created from immigration table and looking up country of origin based on country code (I94CIT)\n",
    "        Fields:\n",
    "        \n",
    "         cicid: integer - unique ID for immigrant based on I94 form\n",
    "         country_of_origin: string - Immigrating from which country\n",
    "         port_of_entry: string - what airport (city) as entry point e.g. NYC, ATL (iata code)\n",
    "         arrival_date: date - date of arrival YYYY-MM-DD \n",
    "         visa: double - visa type e.g. 1.0, 2.0, 3.0\n",
    "         visa_for: string - visa type description - Pleasure, Student, Business\n",
    "         visa_type: string - category of visa type e.g. F1, B2\n",
    "         gender: string - sex M, F, NA\n",
    "         birth_year: integer - 4 digit birth year YYYY to calculate age\n",
    "         occupation: string - occupation, mostly null as CIC not using it\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Project Write Up\n",
    "\n",
    "Final goal was accomplished to process massive amount of I-94 records - all immigration arrival to USA in year 2016.\n",
    "There were 12 SAS files, one for each month, (> 1 M lines). This project builds data lake that can be used by Anlytics\n",
    "team to study immigration pattern by country of origin and possibly co-relate with US city demographics.\n",
    "This would not have been possible from the raw data in different file formats such as SAS, CSV, Text, JSON.\n",
    "\n",
    "##### Technology choice\n",
    "Creating data lake on S3 seemed appropriate choice, it offers flexibility, efficiency and cost effectiveness.\n",
    "This design supports the goal of analytics team have data in a way that can be leveraged to find insights and \n",
    "possibly do predictive analytics.\n",
    "\n",
    "Python, Spark framework are appropriate choice for implementation because of the library support.\n",
    "Spark API offers convinient Read/Write to AWS S3 and course offered several examples, code snippet to help. \n",
    "\n",
    "Spark package 'com.github.saurfang.sas.spark' was used to read 12 I94 SAS('sas7bdt') format files.  However, that caused lot of challenges\n",
    "to use spark to read from S3.  Couldn't get over the Project workspace environment dependency issue with Hadoop version.\n",
    "After many days of futile efforts, wrote python utility program - <b>i94-SAS.py</b> that reads I94 SAS files for each month,\n",
    "and writes back as parquet files.  These parquet files were copied to AWS S3.  \n",
    "I learned the lesson in development environment issues - how time consuming they can be.\n",
    "\n",
    "ETL pipeline is run with immigration-etl.py, it handles reading parquet files from S3 using spark session with 'org.apache.hadoop:hadoop-aws:2.7.0', \n",
    "joining with above mentioned several other data sources and write results back to S3 in parquet format.\n",
    "\n",
    "If I can afford more time at this, there is lot of room for automation. \n",
    "\n",
    "##### Data Refresh\n",
    "ETL script should run at monthly, because I94 data is given for every month, it should be synchronized with new I94 monthly data refreshed.  \n",
    "Immigration and Immigrant table will be refresh monthly.  However, other data is relatively more static (airport codes, city demographics) that can be refreshed\n",
    "less frequently.\n",
    "\n",
    "##### How would I approach the problem differently under the following scenarios:\n",
    "\n",
    "(1) If the data was increased by 100x:        \n",
    "    Work only with small sample to test the ETL pipeline, data flow. I would still use Apache Spark - but run in distributed mode \n",
    "    on a cluster.  Leveraging AWS EC2 (larger cluster with more nodes) with EMR service to handle large amount of processing to handle the data. \n",
    "    Run and store results on cloud (e.g. AWS S3) with full dataset.  Local system will only used with small subset of data.\n",
    "\n",
    "(2) If the pipelines were run on a daily basis by 7am:    \n",
    "    Consider creating 'reporting' data server to not disrupt the production or operations group. If something breaks in production\n",
    "    it can impact organization performance.  Tools like Apache Airflow can be leverged for scheduled run.   \n",
    "\n",
    "(3) If the database needed to be accessed by 100+ people:\n",
    "    Find out if all of these people have same need (common report) or more specific (custom) by division - e.g. Finance, HR, Operations.\n",
    "    If possible, create different views based on this for best performance.\n",
    "    Explore/Research more on Hadoop YARN for High Availibity perspective."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
